{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for drawing out features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "%pylab inline\n",
    "import face_recognition\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\ipykernel_launcher.py\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\n"
     ]
    }
   ],
   "source": [
    "# look where I am\n",
    "print(os.getcwd())\n",
    "print(sys.argv[0])\n",
    "print(os.path.dirname(os.path.realpath('__file__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'all_distances', 'data_landmarks.csv', 'data_landmarks.rar', 'data_landmarks_normalised.csv', 'data_landmarks_normalised_attributes.csv', 'draw_out_features.py.ipynb', 'pairplot.png', 'training.ipynb']\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\\..\n",
      "['.ipynb_checkpoints', '01 - Analysis and Visualisation (Solutions).ipynb', '03 - Classification and Evaluation (Solutions).ipynb', 'Celeb_Faces', 'face_points_index.png', 'Scripts']\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\\..\\Celeb_Faces\n",
      "['640x800_75_b1f3e911-bd00-46db-af91-9334a9477686.webp', 'img_align_celeba', 'list_attr_celeba.csv', 'list_bbox_celeba.csv', 'list_eval_partition.csv', 'list_landmarks_align_celeba.csv']\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\\..\\Celeb_Faces\\img_align_celeba\n",
      "['img_align_celeba']\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\\..\\Celeb_Faces\\img_align_celeba\\img_align_celeba\n",
      "C:\\Users\\James H\\git\\TinderBot\\Database\\Dataset\\Scripts\\..\\..\\..\n"
     ]
    }
   ],
   "source": [
    "# navigate to all data\n",
    "os.path.join(os.path.dirname('__file__'))\n",
    "dir_Scripts            = (os.path.dirname(os.path.realpath('__file__')))\n",
    "print(os.listdir(dir_Scripts))\n",
    "dir_Dataset            = os.path.join(dir_Scripts,\"..\")\n",
    "print(dir_Dataset)\n",
    "print(os.listdir(dir_Dataset))\n",
    "dir_Databse = os.path.join(dir_Dataset,\"..\")\n",
    "dir_root    = os.path.join(dir_Databse,\"..\")\n",
    "dir_Celeb_Faces        = os.path.join(dir_Dataset,\"Celeb_Faces\")\n",
    "print(dir_Celeb_Faces)\n",
    "print(os.listdir(dir_Celeb_Faces))\n",
    "dir_CelebFaces_images  = os.path.join(dir_Celeb_Faces,\"img_align_celeba\")\n",
    "print(dir_CelebFaces_images)\n",
    "print(os.listdir(dir_CelebFaces_images))\n",
    "dir_CelebFaces_images  = os.path.join(dir_CelebFaces_images,\"img_align_celeba\")\n",
    "print(dir_CelebFaces_images)\n",
    "# print(os.listdir(dir_CelebFaces_images))\n",
    "sys.path.append(dir_Scripts)\n",
    "sys.path.append(dir_Dataset)\n",
    "sys.path.append(dir_Celeb_Faces)\n",
    "sys.path.append(dir_CelebFaces_images)\n",
    "sys.path.append(dir_Databse)\n",
    "sys.path.append(dir_root)\n",
    "print(dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(dir_CelebFaces_images)\n",
    "import logging\n",
    "import Logger\n",
    "logger = logging.getLogger(\"Logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image from the dataset\n",
    "def show_landmarks(image_path,dict_landmarks):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "    for landmark in dict_landmarks:\n",
    "        d.polygon(dict_landmarks[landmark],outline='red')\n",
    "    %matplotlib inline\n",
    "    imshow(np.asarray(pil_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    imshow(np.asarray(pil_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    return face_landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(dict):\n",
    "    for key in dict:\n",
    "        print('{}:{}'.format(key,dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the landmark features\n",
    "# image_path = os.path.join(dir_CelebFaces_images,os.listdir(dir_CelebFaces_images)[0])\n",
    "# landmarks_dict = get_landmarks(image_path)[0]\n",
    "# show_landmarks(image_path,landmarks_dict)\n",
    "# print_dict(landmarks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_10_names = os.listdir(dir_CelebFaces_images)\n",
    "images_10_paths = []\n",
    "\n",
    "for image_name in images_10_names:\n",
    "    images_10_paths.append(os.path.join(dir_CelebFaces_images,image_name))\n",
    "\n",
    "rows_list = []\n",
    "names_valid = []\n",
    "\n",
    "for i in range(len(images_10_paths)):\n",
    "    image_path = images_10_paths[i]\n",
    "    landmarks_dict = get_landmarks(image_path) # this is a list of len=1||0\n",
    "    if(len(landmarks_dict)!=0):\n",
    "        landmarks_dict = landmarks_dict[0]\n",
    "        names_valid.append(images_10_names[i])\n",
    "        landmarks_dict['image_id'] = images_10_names[i]\n",
    "        rows_list.append(landmarks_dict)\n",
    "        \n",
    "        \n",
    "df_landmarks = pd.DataFrame(rows_list)\n",
    "# df.to_csv('data_landmarks.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attractive_path = os.path.join(dir_Celeb_Faces,'list_attr_celeba.csv')\n",
    "df_attractive = pd.read_csv(df_attractive_path)\n",
    "\n",
    "# df_attractive_attr = df_attractive[df_attractive['image_id'].isin(names_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# result = pd.concat([df, new_df], axis=1, sort=False)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attractive.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(df_landmarks, df_attractive, on=\"image_id\", how=\"left\")\n",
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('data_landmarks.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv to df\n",
    "data_all = pd.read_csv('data_landmarks.csv')\n",
    "# get valid image names\n",
    "images_valid = data_all['image_id']\n",
    "# format dir of all images\n",
    "images_paths = []\n",
    "for image_name in images_valid:\n",
    "    images_paths.append(os.path.join(dir_CelebFaces_images,image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for formating String to lsit of topules\n",
    "def format_str_to_touples(str_list):\n",
    "    str_list=str_list.replace('[','')\n",
    "    str_list=str_list.replace(']','')\n",
    "    str_list=str_list.replace('(','')\n",
    "    str_list=str_list.replace(')','')\n",
    "    str_list=str_list.replace(' ','')\n",
    "    str_list=str_list.split(',')\n",
    "    str_list=[int(i)for i in str_list]\n",
    "    result = [(str_list[i],str_list[i+1]) for i in range(0,len(str_list),2)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing chin landmarks\n",
    "df_landmarks = data_all.loc[:,'chin':'bottom_lip']\n",
    "chin = df_landmarks['chin'][0]\n",
    "chin = format_str_to_touples(chin)\n",
    "chin_dict = {'chin':chin}\n",
    "show_landmarks(images_paths[0],chin_dict)\n",
    "print(chin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_relative   = []\n",
    "positions_normalized = []\n",
    "\n",
    "df_landmarks       = data_all.loc[:,'chin':'bottom_lip']\n",
    "df_landmarks_cols = (df_landmarks.columns)\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "for i in range(len(images_paths)):\n",
    "    image = face_recognition.load_image_file(images_paths[i])\n",
    "    face_location = face_recognition.face_locations(image)[0]\n",
    "    top, right, bottom, left = face_location\n",
    "    height = abs(top-bottom)\n",
    "    width  = abs(right-left)\n",
    "    dict_rel_norm = {}\n",
    "    for landmark in df_landmarks_cols:\n",
    "        positions_list = df_landmarks[landmark][i]\n",
    "        positions_list_relative   = []\n",
    "        positions_list_normalized = []\n",
    "        positions_list = format_str_to_touples(positions_list)\n",
    "        for x,y in positions_list:\n",
    "            x_rel  = abs(x - width)\n",
    "            x_norm = x_rel / float(width)\n",
    "#             x_norm = float(\"{:.3f}\".format(x_norm))\n",
    "            \n",
    "            y_rel  = abs(y - height)\n",
    "            y_norm = y_rel / float(height)\n",
    "#             y_norm = float(\"{:.2f}\".format(y_norm))\n",
    "            \n",
    "            pos_rel  = (x_rel,y_rel)\n",
    "            pos_norm = (x_norm,y_norm)\n",
    "            \n",
    "            # append to norm & rel landmark\n",
    "            positions_list_relative.append(pos_rel)\n",
    "            positions_list_normalized.append(pos_norm)\n",
    "        \n",
    "        dict_rel_norm['{}_rel'.format(landmark)]=positions_list_relative\n",
    "        dict_rel_norm['{}_norm'.format(landmark)]=positions_list_normalized\n",
    "        dict_rel_norm['image_id'] = data_all['image_id'][i]\n",
    "    df_new = df_new.append(dict_rel_norm, ignore_index=True)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces_locations)\n",
    "print(type(faces_locations[0][0]))\n",
    "\n",
    "top, right, bottom, left = faces_locations[0][0]\n",
    "face_image = image[top:bottom, left:right]\n",
    "pil_image  = Image.fromarray(face_image)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('data_landmarks_normalised.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landmarks_normalised = data_all = pd.read_csv('data_landmarks_normalised.csv')\n",
    "\n",
    "full_df = pd.merge(df_landmarks_normalised, df_attractive, on=\"image_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('data_landmarks_normalised_attributes.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
